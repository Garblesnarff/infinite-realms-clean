# LLM API Keys (at least one required)
OPENAI_API_KEY=your-openai-api-key-here
ANTHROPIC_API_KEY=your-anthropic-api-key-here

# Model Configuration
# You can set different models for different purposes
DEFAULT_LLM=gpt-4-turbo-preview

# Optional: Specify models for specific use cases
# These can be referenced in agents.yaml
CREATIVE_LLM=gpt-4-turbo-preview
VALIDATION_LLM=claude-3-haiku-20240307
FAST_LLM=gpt-3.5-turbo

# Supported OpenAI Models:
# - gpt-4-turbo-preview (recommended for quality)
# - gpt-4 (high quality, slower)
# - gpt-3.5-turbo (fast and cheap)

# Supported Anthropic Models:
# - claude-3-opus-20240229 (highest quality)
# - claude-3-5-sonnet-20241022 (best balance, excellent at writing)
# - claude-3-haiku-20240307 (fast and cheap)

# Local Models (requires Ollama running):
# - ollama/llama2
# - ollama/mistral
# - ollama/codellama
OLLAMA_BASE_URL=http://localhost:11434

# CrewAI Configuration
CREWAI_TELEMETRY_OPT_OUT=true

# Output Configuration
OUTPUT_DIR=./output
ENABLE_PDF_EXPORT=true
ENABLE_JSON_EXPORT=true
ENABLE_OBSIDIAN_EXPORT=true

# ChromaDB Configuration (for consistency checking)
CHROMA_DB_PATH=./data/chroma_db

# Generation Settings
MAX_RETRIES=3
ENABLE_COST_TRACKING=true
LOG_LEVEL=INFO
